import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import seaborn as sns

# Rutas
data_dir = 'Alzheimer_s Dataset'
train_dir = os.path.join(data_dir, 'train')
val_dir = os.path.join(data_dir, 'val')
test_dir = os.path.join(data_dir, 'test')

# Aumento de datos
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
)
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Generadores
img_size = (180, 180)
batch_size = 32

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')
val_generator = val_test_datagen.flow_from_directory(
    val_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical')
test_generator = val_test_datagen.flow_from_directory(
    test_dir, target_size=img_size, batch_size=1, class_mode='categorical', shuffle=False)

class_names = list(train_generator.class_indices.keys())
print("Clases detectadas:", class_names)

# Modelo base con Fine-tuning
base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=Input(shape=(180, 180, 3)))

#  Desbloqueamos las 煤ltimas 30 capas para Fine-tuning
for layer in base_model.layers[:-30]:
    layer.trainable = False
for layer in base_model.layers[-30:]:
    layer.trainable = True

# Modelo completo
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(len(class_names), activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

# Compilaci贸n con learning rate bajo
model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

# Callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
checkpoint = ModelCheckpoint("mejor_modelo.keras", save_best_only=True, verbose=1)

# Entrenamiento
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    callbacks=[early_stop, checkpoint]
)

# Evaluaci贸n en test
loss, acc = model.evaluate(test_generator, verbose=0)
print(f"\n Precisi贸n en el set de prueba: {acc * 100:.2f}%")

# Predicciones
y_pred = model.predict(test_generator)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true = test_generator.classes

# Reporte de clasificaci贸n
print("\n Reporte de Clasificaci贸n:\n")
print(classification_report(y_true, y_pred_labels, target_names=class_names, zero_division=0))

# Matriz de confusi贸n
conf_matrix = confusion_matrix(y_true, y_pred_labels)
plt.figure(figsize=(9, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.title('Matriz de Confusi贸n')
plt.xlabel('Predicci贸n')
plt.ylabel('Real')
plt.show()

# M茅tricas generales
accuracy = accuracy_score(y_true, y_pred_labels)
precision = precision_score(y_true, y_pred_labels, average='weighted', zero_division=0)
recall = recall_score(y_true, y_pred_labels, average='weighted', zero_division=0)
f1 = f1_score(y_true, y_pred_labels, average='weighted', zero_division=0)

print("\n M茅tricas generales:")
print(f" Accuracy: {accuracy:.2f}")
print(f" Precision: {precision:.2f}")
print(f" Recall: {recall:.2f}")
print(f" F1-score: {f1:.2f}")

# Gr谩ficas de entrenamiento
plt.figure(figsize=(14, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Entrenamiento')
plt.plot(history.history['val_accuracy'], label='Validaci贸n')
plt.title('Precisi贸n durante el entrenamiento')
plt.xlabel('pocas')
plt.ylabel('Precisi贸n')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Entrenamiento')
plt.plot(history.history['val_loss'], label='Validaci贸n')
plt.title('P茅rdida durante el entrenamiento')
plt.xlabel('pocas')
plt.ylabel('P茅rdida')
plt.legend()

plt.tight_layout()
plt.show()
